{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecf89714",
   "metadata": {},
   "source": [
    "# Reading JSON Files\n",
    "\n",
    "1. JSON stands for JavaScript Object Notation and was designed as a way for applications and systems to exchage\n",
    "    data between each other.\n",
    "2. JSON is a light-weight text based file format that is very human readable and has the ability to represent data in \n",
    "    a nested format unlike a typical CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc23c29",
   "metadata": {},
   "source": [
    "# Working with Structured Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feed7f56",
   "metadata": {},
   "source": [
    "### Reading a JSON File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78a1b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import ArrayType, FloatType, DateType, BooleanType, StructField, StructType,IntegerType,StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10cf4668",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"ReadinJson\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9294290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_schema = StructType([\n",
    "    StructField(\"id\",IntegerType(),True),\n",
    "    StructField(\"first_name\",StringType(),True),\n",
    "    StructField(\"last_name\",StringType(),True),\n",
    "    StructField(\"fav_movies\",ArrayType(StringType()),True),\n",
    "    StructField(\"salary\",FloatType(),True),\n",
    "    StructField(\"image_url\",StringType(),True),\n",
    "    StructField(\"date_of_birth\",DateType(),True),\n",
    "    StructField(\"active\",BooleanType(),True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af6e893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.json(\"persons.json\",persons_schema,multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ced5a50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- fav_movies: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- salary: float (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- date_of_birth: date (nullable = true)\n",
      " |-- active: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9d3b171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "|  1|     Drucy|    Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|\n",
      "|  2|   Emelyne|    Blaza|[Musketeer, The, ...|3006.04|http://dummyimage...|   1991-11-02| false|\n",
      "|  3|       Max|   Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|\n",
      "|  4|    Ilario|     Kean|[Up Close and Per...|3561.36|http://dummyimage...|   1987-06-09|  true|\n",
      "|  5|     Toddy|   Drexel|[Walk in the Clou...|4934.87|http://dummyimage...|   1992-10-28|  true|\n",
      "|  6|    Oswald| Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false|\n",
      "|  7|    Adrian|   Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false|\n",
      "|  8|  Dominica|  Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|\n",
      "|  9|     Emory|  Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|\n",
      "| 10|  Jeremias|     Bode|[Farewell to Arms...|3472.63|http://dummyimage...|   1997-08-02|  true|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4a49bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+-------------------------------------------------------------+-------+-----------------------------------------------+-------------+------+\n",
      "|id |first_name|last_name|fav_movies                                                   |salary |image_url                                      |date_of_birth|active|\n",
      "+---+----------+---------+-------------------------------------------------------------+-------+-----------------------------------------------+-------------+------+\n",
      "|1  |Drucy     |Poppy    |[I giorni contati]                                           |1463.36|http://dummyimage.com/126x166.png/cc0000/ffffff|1991-02-16   |true  |\n",
      "|2  |Emelyne   |Blaza    |[Musketeer, The, Topralli]                                   |3006.04|http://dummyimage.com/158x106.bmp/cc0000/ffffff|1991-11-02   |false |\n",
      "|3  |Max       |Rettie   |[The Forgotten Space, Make It Happen]                        |1422.88|http://dummyimage.com/237x140.jpg/ff4444/ffffff|1990-03-03   |false |\n",
      "|4  |Ilario    |Kean     |[Up Close and Personal]                                      |3561.36|http://dummyimage.com/207x121.jpg/cc0000/ffffff|1987-06-09   |true  |\n",
      "|5  |Toddy     |Drexel   |[Walk in the Clouds, A]                                      |4934.87|http://dummyimage.com/116x202.png/cc0000/ffffff|1992-10-28   |true  |\n",
      "|6  |Oswald    |Petrolli |[Wing and the Thigh, The (L'aile ou la cuisse)]              |1153.23|http://dummyimage.com/137x172.jpg/5fa2dd/ffffff|1986-09-02   |false |\n",
      "|7  |Adrian    |Clarey   |[Walking Tall, Paradise, Hawaiian Style]                     |1044.73|http://dummyimage.com/244x218.bmp/cc0000/ffffff|1971-08-24   |false |\n",
      "|8  |Dominica  |Goodnow  |[Hearts Divided]                                             |1147.76|http://dummyimage.com/112x203.jpg/dddddd/000000|1973-08-27   |false |\n",
      "|9  |Emory     |Slocomb  |[Snake and Crane Arts of Shaolin (She hao ba bu), Mala Noche]|1082.11|http://dummyimage.com/138x226.jpg/cc0000/ffffff|1974-06-08   |true  |\n",
      "|10 |Jeremias  |Bode     |[Farewell to Arms, A]                                        |3472.63|http://dummyimage.com/243x108.bmp/dddddd/000000|1997-08-02   |true  |\n",
      "+---+----------+---------+-------------------------------------------------------------+-------+-----------------------------------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fd1083",
   "metadata": {},
   "source": [
    "# Columns and Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbb40e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a180e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+\n",
      "|first_name|last_name|date_of_birth|\n",
      "+----------+---------+-------------+\n",
      "|     Drucy|    Poppy|   1991-02-16|\n",
      "|   Emelyne|    Blaza|   1991-11-02|\n",
      "|       Max|   Rettie|   1990-03-03|\n",
      "|    Ilario|     Kean|   1987-06-09|\n",
      "|     Toddy|   Drexel|   1992-10-28|\n",
      "+----------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(col(\"first_name\"),col(\"last_name\"),col(\"date_of_birth\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ab190c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+\n",
      "|first_name|last_name|date_of_birth|\n",
      "+----------+---------+-------------+\n",
      "|     Drucy|    Poppy|   1991-02-16|\n",
      "|   Emelyne|    Blaza|   1991-11-02|\n",
      "|       Max|   Rettie|   1990-03-03|\n",
      "|    Ilario|     Kean|   1987-06-09|\n",
      "|     Toddy|   Drexel|   1992-10-28|\n",
      "+----------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(expr(\"first_name\"),expr(\"last_name\"),expr(\"date_of_birth\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aef45e",
   "metadata": {},
   "source": [
    "### pyspark.sql.functions provide two functions concat() and concat_ws() to concatenate DataFrame multiple columns into a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24bc682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a51f9318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+------------------+\n",
      "|       full_name| salary|   salary_increase|\n",
      "+----------------+-------+------------------+\n",
      "|     Drucy Poppy|1463.36|1609.6959838867188|\n",
      "|   Emelyne Blaza|3006.04|  3306.64404296875|\n",
      "|      Max Rettie|1422.88|1565.1680053710938|\n",
      "|     Ilario Kean|3561.36|3917.4961181640624|\n",
      "|    Toddy Drexel|4934.87|  5428.35712890625|\n",
      "| Oswald Petrolli|1153.23| 1268.552978515625|\n",
      "|   Adrian Clarey|1044.73| 1149.202978515625|\n",
      "|Dominica Goodnow|1147.76|1262.5360107421875|\n",
      "|   Emory Slocomb|1082.11|1190.3209838867188|\n",
      "|   Jeremias Bode|3472.63|  3819.89287109375|\n",
      "+----------------+-------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(concat_ws(' ', col(\"first_name\"),col(\"last_name\")).alias(\"full_name\"),\n",
    "            col(\"salary\"),\n",
    "            (col(\"salary\")* 0.10 + col(\"salary\")).alias(\"salary_increase\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd442b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+------------------+\n",
      "|         full_name| salary|   salary_increase|\n",
      "+------------------+-------+------------------+\n",
      "|       Drucy Poppy|1463.36|1609.6959838867188|\n",
      "|     Emelyne Blaza|3006.04|  3306.64404296875|\n",
      "|        Max Rettie|1422.88|1565.1680053710938|\n",
      "|       Ilario Kean|3561.36|3917.4961181640624|\n",
      "|      Toddy Drexel|4934.87|  5428.35712890625|\n",
      "|   Oswald Petrolli|1153.23| 1268.552978515625|\n",
      "|     Adrian Clarey|1044.73| 1149.202978515625|\n",
      "|  Dominica Goodnow|1147.76|1262.5360107421875|\n",
      "|     Emory Slocomb|1082.11|1190.3209838867188|\n",
      "|     Jeremias Bode|3472.63|  3819.89287109375|\n",
      "|    Timothy Ervine|1147.61|1262.3709838867187|\n",
      "|    Leanora Gooder|1327.02| 1459.722021484375|\n",
      "|   Claiborn Denham|2623.33|   2885.6630859375|\n",
      "|  Ambrosi Vidineev|4550.88|  5005.96787109375|\n",
      "|Feodor Nancekivell|2218.46|  2440.30595703125|\n",
      "|  Margaux Archbold|1013.75|          1115.125|\n",
      "|   Balduin Elstone|2302.26|2532.4860107421873|\n",
      "|    Alfie Hatliffe| 3893.1| 4282.410107421875|\n",
      "|       Lura Follis|3331.26|3664.3860107421874|\n",
      "|        Maxi Cluet|4046.46|  4451.10595703125|\n",
      "+------------------+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(concat_ws(' ', col(\"first_name\"),col(\"last_name\")).alias(\"full_name\"),\n",
    "            col(\"salary\"),\n",
    "            expr(\"salary * 0.10 + salary\").alias(\"salary_increase\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcbfc0e",
   "metadata": {},
   "source": [
    "# Filter and Where Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c71eafe",
   "metadata": {},
   "source": [
    "### Learn to filter data using the \"FILTER\", \"WHERE\" functions. FYI, these are built in DataFrame API functions such as \"SELECT, ORDER BY, GROUP BY, FILTER, WHERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82f77efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|  last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "|  1|     Drucy|      Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|\n",
      "|  3|       Max|     Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|\n",
      "|  6|    Oswald|   Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false|\n",
      "|  7|    Adrian|     Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false|\n",
      "|  8|  Dominica|    Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|\n",
      "|  9|     Emory|    Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|\n",
      "| 11|   Timothy|     Ervine|[Land of the Lost...|1147.61|http://dummyimage...|   1971-06-02| false|\n",
      "| 12|   Leanora|     Gooder|[It's All About L...|1327.02|http://dummyimage...|   1981-12-17| false|\n",
      "| 13|  Claiborn|     Denham|[McCullin, Max Pa...|2623.33|http://dummyimage...|   1996-03-07| false|\n",
      "| 15|    Feodor|Nancekivell|   [Monsoon Wedding]|2218.46|http://dummyimage...|   2000-10-07| false|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.filter(\"salary <= 3000\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0afc235f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "|  1|     Drucy|    Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|\n",
      "|  9|     Emory|  Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|\n",
      "| 16|   Margaux| Archbold|[And Now a Word f...|1013.75|http://dummyimage...|   1988-07-29|  true|\n",
      "| 26|     Clive|      Lax|             [Rabid]|2126.87|http://dummyimage...|   1981-10-26|  true|\n",
      "| 33|  Sherline|  Primett|   [Jungle Fighters]|2309.39|http://dummyimage...|   1972-07-23|  true|\n",
      "| 34|     Davis|    Pinks|          [Hounddog]|1337.14|http://dummyimage...|   1989-07-27|  true|\n",
      "| 37|    Carlen|  Sharply|[Dr. Jekyll and M...|2051.85|http://dummyimage...|   2002-06-01|  true|\n",
      "| 40|    Jordan|   Lorant|[Shockproof, Bach...|2183.91|http://dummyimage...|   1979-07-29|  true|\n",
      "| 49| Kendricks|      Kee|   [Flower & Garnet]|2304.39|http://dummyimage...|   1999-11-14|  true|\n",
      "| 57|   Krystle|  Shovell|[Doomsday, Flight...|2260.76|http://dummyimage...|   1987-09-01|  true|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.where((col(\"salary\") <= 3000)& (col(\"active\") == True)).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a46a5277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9224238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|  last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| 14|   Ambrosi|   Vidineev|[Wall Street: Mon...|4550.88|http://dummyimage...|   1989-07-20|  true|\n",
      "| 15|    Feodor|Nancekivell|   [Monsoon Wedding]|2218.46|http://dummyimage...|   2000-10-07| false|\n",
      "| 18|     Alfie|   Hatliffe|     [Lord of Tears]| 3893.1|http://dummyimage...|   1989-06-21|  true|\n",
      "| 25|     Kelcy|     Wogdon|    [Iron Mask, The]|4512.51|http://dummyimage...|   2000-10-20|  true|\n",
      "| 32|      Redd|   Akenhead|[Century of the D...| 2470.9|http://dummyimage...|   2000-06-05| false|\n",
      "| 34|     Davis|      Pinks|          [Hounddog]|1337.14|http://dummyimage...|   1989-07-27|  true|\n",
      "| 61|    Shanna|    Samples|[Thomas in Love (...| 2703.0|http://dummyimage...|   1989-07-07| false|\n",
      "| 69|  Annabell|    Doughty|[Entertaining Ang...|2022.57|http://dummyimage...|   2000-09-03|  true|\n",
      "| 74|     Micky|     Umfrey|[Haunted House, T...|1271.82|http://dummyimage...|   1989-07-04| false|\n",
      "| 88|     Jobie|    Maughan|[Devils on the Do...| 3899.2|http://dummyimage...|   2000-02-07| false|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.filter((year(\"date_of_birth\") == 2000) | (year(\"date_of_birth\") == 1989)).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2660ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4164ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| 11|   Timothy|   Ervine|[Land of the Lost...|1147.61|http://dummyimage...|   1971-06-02| false|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.where(array_contains(data.fav_movies,\"Land of the Lost\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5e8914",
   "metadata": {},
   "source": [
    "# Distict, Drop, Duplicates, Order By"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36432c96",
   "metadata": {},
   "source": [
    "Learn how to get unique set of rows, drop duplicates and sort/ order the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "715bcab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02489067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|active|\n",
      "+------+\n",
      "|  true|\n",
      "| false|\n",
      "| false|\n",
      "|  true|\n",
      "|  true|\n",
      "| false|\n",
      "| false|\n",
      "| false|\n",
      "|  true|\n",
      "|  true|\n",
      "+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(\"active\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a350d9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|active|\n",
      "+------+\n",
      "|  true|\n",
      "| false|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(\"active\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e13f3ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+\n",
      "|first_name|year|active|\n",
      "+----------+----+------+\n",
      "|    Adrian|1971| false|\n",
      "|   Feodora|1971|  true|\n",
      "|       Sky|1971| false|\n",
      "|   Timothy|1971| false|\n",
      "|    Lucita|1972|  true|\n",
      "|      Rodi|1972| false|\n",
      "|  Sherline|1972|  true|\n",
      "|     Toddy|1972|  true|\n",
      "|  Dominica|1973| false|\n",
      "|    Kelila|1973|  true|\n",
      "+----------+----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(col(\"first_name\"),\n",
    "           year(col(\"date_of_birth\")).alias(\"year\"),\n",
    "           col(\"active\")).orderBy(\"year\",\"first_name\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d0e0643",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_df = data.select(col(\"first_name\"),\n",
    "                        year(col(\"date_of_birth\")).alias(\"year\"),\n",
    "                        col(\"active\")).dropDuplicates([\"year\",\"active\"]).orderBy(\"year\", \"first_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a819837d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+\n",
      "|first_name|year|active|\n",
      "+----------+----+------+\n",
      "|    Adrian|1971| false|\n",
      "|   Feodora|1971|  true|\n",
      "|      Rodi|1972| false|\n",
      "|  Sherline|1972|  true|\n",
      "|  Dominica|1973| false|\n",
      "|    Kelila|1973|  true|\n",
      "|   Balduin|1974| false|\n",
      "|     Emory|1974|  true|\n",
      "|    Janean|1975|  true|\n",
      "|       Bev|1976|  true|\n",
      "| Franciska|1976| false|\n",
      "|     Johny|1977| false|\n",
      "|    Daveta|1978| false|\n",
      "|   Guthrie|1978|  true|\n",
      "|      Maxi|1979| false|\n",
      "|   Melinda|1979|  true|\n",
      "|    Carter|1980| false|\n",
      "|   Loralyn|1980|  true|\n",
      "|     Clive|1981|  true|\n",
      "|   Leanora|1981| false|\n",
      "+----------+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropped_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6ecac24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+\n",
      "|first_name|year|active|\n",
      "+----------+----+------+\n",
      "|     Daron|2002|  true|\n",
      "|    Virgie|2002|  true|\n",
      "|    Carlen|2002|  true|\n",
      "|   Lorilee|2002| false|\n",
      "|    Maxine|2001| false|\n",
      "|    Feodor|2000| false|\n",
      "|     Kelcy|2000|  true|\n",
      "|  Annabell|2000|  true|\n",
      "|      Redd|2000| false|\n",
      "|     Jobie|2000| false|\n",
      "+----------+----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(col(\"first_name\"),\n",
    "                        year(col(\"date_of_birth\")).alias(\"year\"),\n",
    "                        col(\"active\")).orderBy(\"year\",ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7db08f",
   "metadata": {},
   "source": [
    "# Rows and Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b34f79a",
   "metadata": {},
   "source": [
    "How to crate indivisual rows and make dataframe out of the rows, and use the union transforamtion to combine dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6fea493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3da33ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_row = Row(101, \"Robert\",\"Ownes\",\n",
    "                 [\"Men in Black III\",\"Home Alone\"],4300.64,\"http://someimage.com\",\"1964-08-18\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c8f3a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_rows_list = [Row(102, \"Kenny\",\"Bobien\",\n",
    "                     [\"Men in Black III\",\"Home Alone\"],4300.64,\"http://someimage.com\",\"1964-08-18\",True),\n",
    "                   Row(103, \"Sara\",\"Devine\",\n",
    "                     [\"Men in Black III\",\"Home Alone\"],4300.64,\"http://someimage.com\",\"1964-08-18\",True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e448bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_rows_list.append(person_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f28ab66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Row(102, 'Kenny', 'Bobien', ['Men in Black III', 'Home Alone'], 4300.64, 'http://someimage.com', '1964-08-18', True)>, <Row(103, 'Sara', 'Devine', ['Men in Black III', 'Home Alone'], 4300.64, 'http://someimage.com', '1964-08-18', True)>, <Row(101, 'Robert', 'Ownes', ['Men in Black III', 'Home Alone'], 4300.64, 'http://someimage.com', '1964-08-18', True)>]\n"
     ]
    }
   ],
   "source": [
    "print(person_rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "367fbc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Robert'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af88c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_person_df = spark.createDataFrame(person_rows_list,[\"id\",\"first_name\",\"last_name\",\"fav_movies\",\"salary\",\"image_url\",\"date_of_birth\",\"active\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ad31e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+------------------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies|            salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+------------------+--------------------+-------------+------+\n",
      "|103|      Sara|   Devine|[Men in Black III...|           4300.64|http://someimage.com|   1964-08-18|  true|\n",
      "|102|     Kenny|   Bobien|[Men in Black III...|           4300.64|http://someimage.com|   1964-08-18|  true|\n",
      "|101|    Robert|    Ownes|[Men in Black III...|           4300.64|http://someimage.com|   1964-08-18|  true|\n",
      "|100|    Virgie| Domanski|[Horseman, The, S...| 2165.929931640625|http://dummyimage...|   2002-01-05|  true|\n",
      "| 99|   Rozalie|   Wannop|[Suddenly, The No...|1259.6400146484375|http://dummyimage...|   1997-03-25| false|\n",
      "| 98|     Davin|     Labb|[Viva Riva!, Kill...| 1452.739990234375|http://dummyimage...|   1988-01-27|  true|\n",
      "| 97|      Rodi|   Farnan|[Code, The (Menta...|   2325.8798828125|http://dummyimage...|   1972-01-04| false|\n",
      "| 96|       Dew| Coopland|              [Rush]|  2725.56005859375|http://dummyimage...|   1986-11-14| false|\n",
      "| 95|      Cobb|  MacLure|[Storage 24, His ...|1621.1700439453125|http://dummyimage...|   1994-06-28| false|\n",
      "| 94|    Bennie|   Knight|[House on Carroll...| 2370.239990234375|http://dummyimage...|   1977-08-27| false|\n",
      "| 93|    Janean|     Pelz|              [Once]|    4906.919921875|http://dummyimage...|   1975-09-23|  true|\n",
      "| 92|     Daron|  Briance|[Train on the Bra...|  4226.35009765625|http://dummyimage...|   2002-02-22|  true|\n",
      "| 91|   Stanley|Sargeaunt|[Blow Out, Ashes,...| 2958.639892578125|http://dummyimage...|   1986-09-12| false|\n",
      "| 90|      Josy|   Pellew|[Dominion: Preque...|   2791.5400390625|http://dummyimage...|   1981-01-14| false|\n",
      "| 89|      Tish|   Machon|  [Arrowhead, Simon]|  4830.06005859375|http://dummyimage...|   1995-06-08|  true|\n",
      "| 88|     Jobie|  Maughan|[Devils on the Do...| 3899.199951171875|http://dummyimage...|   2000-02-07| false|\n",
      "| 87| Margareta|  Marusik|[Eyjafjallaj√∂kull...| 3416.969970703125|http://dummyimage...|   1983-10-01| false|\n",
      "| 86|    Welbie|  Crackel|[All That Heaven ...| 2720.280029296875|http://dummyimage...|   1990-10-24|  true|\n",
      "| 85|    Maxine|  Ewenson|[Savior, Beaver T...|            3363.5|http://dummyimage...|   2001-01-24| false|\n",
      "| 84|     Ricca| Newgrosh|[Documentarian, D...|  3412.06005859375|http://dummyimage...|   1984-07-27| false|\n",
      "+---+----------+---------+--------------------+------------------+--------------------+-------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_person_df = data.union(new_person_df)\n",
    "add_person_df.sort(desc(\"id\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb5f76f",
   "metadata": {},
   "source": [
    "# Adding,Renaming and Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acff6449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee114ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_persons_df1 = data.withColumn(\"salary_increase\",expr(\"salary * 0.10 + salary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41680130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'first_name',\n",
       " 'last_name',\n",
       " 'fav_movies',\n",
       " 'salary',\n",
       " 'image_url',\n",
       " 'date_of_birth',\n",
       " 'active',\n",
       " 'salary_increase']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_persons_df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7854a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_persons_df2 = (aug_persons_df1\n",
    "                    .withColumn(\"birth_year\",year(\"date_of_birth\"))\n",
    "                    .withColumnRenamed(\"fav_movies\",\"movies\")\n",
    "                    .withColumn(\"salary_x10\",round(col(\"salary_increase\"),2))\n",
    "                    .drop(\"salary_increase\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d95f6f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+----------+----------+\n",
      "| id|first_name|last_name|              movies| salary|           image_url|date_of_birth|active|birth_year|salary_x10|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+----------+----------+\n",
      "|  1|     Drucy|    Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|      1991|    1609.7|\n",
      "|  2|   Emelyne|    Blaza|[Musketeer, The, ...|3006.04|http://dummyimage...|   1991-11-02| false|      1991|   3306.64|\n",
      "|  3|       Max|   Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|      1990|   1565.17|\n",
      "|  4|    Ilario|     Kean|[Up Close and Per...|3561.36|http://dummyimage...|   1987-06-09|  true|      1987|    3917.5|\n",
      "|  5|     Toddy|   Drexel|[Walk in the Clou...|4934.87|http://dummyimage...|   1992-10-28|  true|      1992|   5428.36|\n",
      "|  6|    Oswald| Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false|      1986|   1268.55|\n",
      "|  7|    Adrian|   Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false|      1971|    1149.2|\n",
      "|  8|  Dominica|  Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|      1973|   1262.54|\n",
      "|  9|     Emory|  Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|      1974|   1190.32|\n",
      "| 10|  Jeremias|     Bode|[Farewell to Arms...|3472.63|http://dummyimage...|   1997-08-02|  true|      1997|   3819.89|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aug_persons_df2.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19b8da7",
   "metadata": {},
   "source": [
    "# Working with Missing or Bad Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cfc21e",
   "metadata": {},
   "source": [
    "how to clean the dataframe and remove missing or bad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71afd694",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_movies_list = [Row(None,None,None),\n",
    "                  Row(None, None, 2020),\n",
    "                  Row(\"Jone Doe\",\"Awesome movie\",None),\n",
    "                  Row(None, \"Awesome Movie\",2021),\n",
    "                  Row(\"Mary Jane\",None,2019),\n",
    "                  Row(\"vikter Duplaix\",\"Not another teen movie\",2001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65208e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Row(None, None, None)>,\n",
       " <Row(None, None, 2020)>,\n",
       " <Row('Jone Doe', 'Awesome movie', None)>,\n",
       " <Row(None, 'Awesome Movie', 2021)>,\n",
       " <Row('Mary Jane', None, 2019)>,\n",
       " <Row('vikter Duplaix', 'Not another teen movie', 2001)>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_movies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6250c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_movies_columns = [\"actor_name\",\"movie_title\",\"produced_year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c7d7d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_movies_df = spark.createDataFrame(bad_movies_list, schema=bad_movies_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2824e5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------+\n",
      "|    actor_name|         movie_title|produced_year|\n",
      "+--------------+--------------------+-------------+\n",
      "|          null|                null|         null|\n",
      "|          null|                null|         2020|\n",
      "|      Jone Doe|       Awesome movie|         null|\n",
      "|          null|       Awesome Movie|         2021|\n",
      "|     Mary Jane|                null|         2019|\n",
      "|vikter Duplaix|Not another teen ...|         2001|\n",
      "+--------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c532065e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------+\n",
      "|    actor_name|         movie_title|produced_year|\n",
      "+--------------+--------------------+-------------+\n",
      "|vikter Duplaix|Not another teen ...|         2001|\n",
      "+--------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c02932f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------+\n",
      "|    actor_name|         movie_title|produced_year|\n",
      "+--------------+--------------------+-------------+\n",
      "|vikter Duplaix|Not another teen ...|         2001|\n",
      "+--------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.na.drop(\"any\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1f4537dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------+\n",
      "|    actor_name|         movie_title|produced_year|\n",
      "+--------------+--------------------+-------------+\n",
      "|          null|                null|         2020|\n",
      "|      Jone Doe|       Awesome movie|         null|\n",
      "|          null|       Awesome Movie|         2021|\n",
      "|     Mary Jane|                null|         2019|\n",
      "|vikter Duplaix|Not another teen ...|         2001|\n",
      "+--------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.na.drop(\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5cd43eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------+\n",
      "|    actor_name|         movie_title|produced_year|\n",
      "+--------------+--------------------+-------------+\n",
      "|      Jone Doe|       Awesome movie|         null|\n",
      "|     Mary Jane|                null|         2019|\n",
      "|vikter Duplaix|Not another teen ...|         2001|\n",
      "+--------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.filter(col(\"actor_name\").isNull() != True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99f73b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-------------+\n",
      "|actor_name|  movie_title|produced_year|\n",
      "+----------+-------------+-------------+\n",
      "|      null|         null|         null|\n",
      "|      null|         null|         2020|\n",
      "|      null|Awesome Movie|         2021|\n",
      "+----------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.filter(col(\"actor_name\").isNull() != False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0eee3e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|    produced_year|\n",
      "+-------+-----------------+\n",
      "|  count|                4|\n",
      "|   mean|          2015.25|\n",
      "| stddev|9.535023160258536|\n",
      "|    min|             2001|\n",
      "|    max|             2021|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.describe(\"produced_year\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd7e1f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|summary|    actor_name|\n",
      "+-------+--------------+\n",
      "|  count|             3|\n",
      "|   mean|          null|\n",
      "| stddev|          null|\n",
      "|    min|      Jone Doe|\n",
      "|    max|vikter Duplaix|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.describe(\"actor_name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fff0361",
   "metadata": {},
   "source": [
    "## Working with User Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7a7d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7402b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_list = [(\"Joe\", 85),\n",
    "               (\"Jane\", 90),\n",
    "               (\"Mary\", 55)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "85703cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_columns = [\"name\",\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "498d01fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df = spark.createDataFrame(student_list, schema=students_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9d51c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|name|score|\n",
      "+----+-----+\n",
      "| Joe|   85|\n",
      "|Jane|   90|\n",
      "|Mary|   55|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "309f9d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterGrade(score:int):\n",
    "    grade = ''\n",
    "    if score > 100:\n",
    "        grade = \"cheating\"\n",
    "    elif score >= 90:\n",
    "        grade = \"A\"\n",
    "    elif score >=80:\n",
    "        grade = \"B\"\n",
    "    elif score >= 70:\n",
    "        grade = \"C\"\n",
    "    else:\n",
    "        grade = \"Fail\"\n",
    "    return grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "42c02174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    }
   ],
   "source": [
    "print(letterGrade(75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ac3e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "letterGradeUDF =udf(letterGrade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "479f902b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|name|score|grade|\n",
      "+----+-----+-----+\n",
      "| Joe|   85|    B|\n",
      "|Jane|   90|    A|\n",
      "|Mary|   55| Fail|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.select(\"name\", \"score\", letterGradeUDF(col(\"score\")).alias(\"grade\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5f40e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b31b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
